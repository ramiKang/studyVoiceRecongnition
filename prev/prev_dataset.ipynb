{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb15609-e84b-466d-bedd-03371ece9f9f",
   "metadata": {},
   "source": [
    "## Make Datasets\n",
    "하다하다 못해먹겠어서 내가 직접 만드는 데이트셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b7a067-8a09-49ee-a4bb-55e3d9d0476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/haram/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/haram/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/haram/.local/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /home/haram/.local/lib/python3.10/site-packages (from datasets) (3.13.4)\n",
      "Requirement already satisfied: pandas in /home/haram/.local/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/haram/.local/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/haram/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/haram/.local/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/haram/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /home/haram/.local/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/haram/.local/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: aiohttp in /home/haram/.local/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/haram/.local/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/haram/.local/lib/python3.10/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/haram/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/haram/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/haram/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/haram/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/haram/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/haram/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bbfff4-026e-4f71-a21a-3881539bcc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haram/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-18 20:09:55.552662: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-18 20:09:55.605315: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-18 20:09:55.605362: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-18 20:09:55.605426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-18 20:09:55.616911: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datasets import Dataset, Audio\n",
    "\n",
    "# import\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC, AutoProcessor,Wav2Vec2CTCTokenizer,Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c75a813-63c3-42f8-a514-9084a4b26648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 파일 경로\n",
    "json_file_path = \"./data/exist_test/rami_mapping.json\"\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    mapping_Data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cbf5680-20d3-44ca-8c7c-a4b452fe6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mapping_Data)\n",
    "\n",
    "\n",
    "# change name\n",
    "df = df.rename(columns={\"path\": \"audio\"})\n",
    "\n",
    "# dataset = Dataset.from_pandas(df).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d7908d-07fe-4a8c-9b70-21b2c6109d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "model_name = \"facebook/wav2vec2-base-960h\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb3169f-4bec-416f-b2a0-03fa6357bf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcription'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    batch[\"input_values\"] = []\n",
    "    batch[\"input_length\"] = []\n",
    "    \n",
    "    for audio in batch[\"audio\"]:\n",
    "        input_values = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "        input_length = len(input_values)\n",
    "        \n",
    "        batch[\"input_values\"].append(input_values)\n",
    "        batch[\"input_length\"].append(input_length)\n",
    "    \n",
    "\n",
    "    print(\"tra\",batch[\"transcription\"])\n",
    "    batch[\"labels\"] = processor(text=batch[\"transcription\"]).input_id\n",
    "    return batch\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset.set_transform(prepare_dataset)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4b9a46-96ef-46eb-877d-a2c0340c1ce0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'common_voice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 각 예제에 대해 평가 수행\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcommon_voice\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 오디오 파일 경로\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     audio_path \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# 오디오 파일 로드\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'common_voice' is not defined"
     ]
    }
   ],
   "source": [
    "# 각 예제에 대해 평가 수행\n",
    "for example in dataset:\n",
    "    # 오디오 파일 경로\n",
    "    audio_path = example[\"audio\"]\n",
    "    # 오디오 파일 로드\n",
    "    speech, _ = torchaudio.load(audio_path)\n",
    "    # 모델 입력값으로 변환\n",
    "    inputs = processor(input_data=speech, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    # 모델 추론\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    # CTC 디코딩을 사용하여 텍스트로 변환\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    # 정답과 비교하여 정확도 업데이트\n",
    "    if transcription[0] == example[\"transcription\"]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# 정확도 출력\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HYU-GPU",
   "language": "python",
   "name": "hyu-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
